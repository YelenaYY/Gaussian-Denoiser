{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d448c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "270ab56f-9f2f-4b94-ba79-64c571d1caec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from torch.utils.data.dataset import Dataset  # noqa:E402\n",
    "from torchvision.io import decode_image  # noqa:E402\n",
    "from torchvision import transforms  # noqa:E402\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path  # noqa:E402\n",
    "from unit_test import TestAssertions, unit_test, run_unit_tests  # noqa:E402\n",
    "import random\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4f965cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = Path(\"checkpoints\")\n",
    "MAX_EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "05986864-da93-41d6-879f-4ff77770832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "# Check if cuda device is available\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "use_cuda = torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cf97a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded and extracted to data/\n"
     ]
    }
   ],
   "source": [
    "!bash download_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d748799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 321, 481])\n"
     ]
    }
   ],
   "source": [
    "# read any image from the data/BSDS300/image/train folder\n",
    "image_path = Path(\"data/BSDS300/images/train/2092.jpg\")\n",
    "image = decode_image(str(image_path))\n",
    "print(image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b469c361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cfa18854-615e-464b-b0e0-a9e2b83f928a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 unit tests\n",
      "----------------------------------------\n",
      "Running test: dataset_loading_and_indexing\n",
      "✓ dataset_loading_and_indexing passed\n",
      "Running test: dataset_transform_cropping\n",
      "✓ dataset_transform_cropping passed\n",
      "Running test: dataset_transform_patch_cropping\n",
      "✓ dataset_transform_patch_cropping passed\n",
      "Running test: read_all_patches\n",
      "torch.Size([204800, 1, 40, 40])\n",
      "✓ read_all_patches passed\n",
      "----------------------------------------\n",
      "Tests run: 4, Passed: 4, Failed: 0\n"
     ]
    }
   ],
   "source": [
    "from abc import abstractmethod\n",
    "\n",
    "\n",
    "class ExtractPatch():\n",
    "    @abstractmethod\n",
    "    def extract_patches(self, idx, patch_size, stride, batch_size=128):\n",
    "        pass\n",
    "\n",
    "class Bsd300(Dataset):\n",
    "    def __init__(self, data_folder, transform=None):\n",
    "        self.data_folder = Path(data_folder)\n",
    "        self.transform = transform\n",
    "        self.labels = []\n",
    "        with open(self.data_folder / \"iids_train.txt\") as f:\n",
    "            self.labels = f.readlines()\n",
    "        if len(self.labels) == 0:\n",
    "            print(\"No labels found in\", data_folder)\n",
    "\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        img_name = self.data_folder / f\"images/train/{label.strip()}.jpg\"\n",
    "        image = decode_image(str(img_name))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "class Train400(Dataset, ExtractPatch):\n",
    "    def __init__(self, data_folder, transform=None):\n",
    "        self.data_folder = Path(data_folder)\n",
    "        self.transform = transform\n",
    "        # list get file stems in the data_folder/train400 folder\n",
    "        self.labels = [f.stem for f in self.data_folder.glob(\"*.png\")]\n",
    "        if len(self.labels) == 0:\n",
    "            raise FileNotFoundError(f\"No images found in {data_folder}\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        img_name = self.data_folder / f\"{label}.png\"\n",
    "        image = decode_image(str(img_name))\n",
    "        return image, label\n",
    "    \n",
    "    def extract_patches(self, idx, patch_size, stride, batch_size):\n",
    "        image, label = self.__getitem__(idx)\n",
    "        patches = []\n",
    "        for i in range(0, image.shape[1] - patch_size + 1, stride):\n",
    "            for j in range(0, image.shape[2] - patch_size + 1, stride):\n",
    "                patch = image[:,i:i+patch_size, j:j+patch_size]\n",
    "                if self.transform:\n",
    "                    patch = self.transform(patch)\n",
    "                patches.append(patch)\n",
    "        \n",
    "        n_patches_to_remove_for_batch_normalization = len(patches) % batch_size\n",
    "        patches = patches[:-n_patches_to_remove_for_batch_normalization]\n",
    "        patches = torch.stack(patches)\n",
    "        return patches, label\n",
    "    \n",
    "    def read_all_patches(self, patch_size, stride, batch_size=128):\n",
    "        all_patches = []\n",
    "        for i in range(len(self)):\n",
    "            patches, _ = self.extract_patches(i, patch_size, stride, batch_size)\n",
    "            all_patches.append(patches)\n",
    "        return torch.cat(all_patches)\n",
    "\n",
    "\n",
    "class NoisyPatchDataset(Dataset):\n",
    "    def __init__(self, patches, sigma: float | tuple[float, float]=25):\n",
    "        self.patches = patches\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.patches.size(0)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        patches = self.patches[idx]\n",
    "        if isinstance(self.sigma, tuple): # sigma is a tuple of two floats\n",
    "            sigma = random.uniform(self.sigma[0], self.sigma[1])\n",
    "            noisy_patches = patches + torch.randn_like(patches) * sigma\n",
    "        elif isinstance(self.sigma, float): # sigma is a float\n",
    "            noisy_patches = patches + torch.randn_like(patches) * self.sigma\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid noise sigma type: {type(self.sigma)}\")\n",
    "\n",
    "        return noisy_patches, patches\n",
    "\n",
    "class Tests:\n",
    "    @staticmethod\n",
    "    @unit_test\n",
    "    def dataset_loading_and_indexing():\n",
    "        dataset = Bsd300(\"data/BSDS300\")\n",
    "        TestAssertions.assert_eq(len(dataset), 200, \"Dataset should have = 200 images\")\n",
    "        _, _ = dataset[0] \n",
    "        dataset = Train400(\"data/Train400\")\n",
    "        TestAssertions.assert_eq(len(dataset), 400, \"Dataset should have = 400 images\")\n",
    "        _, _ = dataset[0]\n",
    "    \n",
    "    @staticmethod\n",
    "    @unit_test\n",
    "    def dataset_transform_cropping():\n",
    "        dataset = Bsd300(\"data/BSDS300\", transform=transforms.RandomCrop(180))\n",
    "        for i in range(len(dataset)):\n",
    "            image, _ = dataset[i]\n",
    "            TestAssertions.assert_eq(image.shape[1], 180, \"Image H should be cropped to 180\")\n",
    "            TestAssertions.assert_eq(image.shape[2], 180, \"Image W should be cropped to 180\")\n",
    "    \n",
    "    @staticmethod\n",
    "    @unit_test\n",
    "    def dataset_transform_patch_cropping():\n",
    "        transform = transforms.RandomChoice([\n",
    "            transforms.RandomRotation((90, 90)),\n",
    "        ])\n",
    "        dataset = Train400(\"data/Train400\", transform=transform)\n",
    "        stride = 6\n",
    "        patches, label = dataset.extract_patches(0, patch_size=40, stride=stride, batch_size=128)\n",
    "        patch1 = patches[0,:,:,:]\n",
    "\n",
    "        dataset = Train400(\"data/Train400\")\n",
    "        stride = 6\n",
    "        patches, label = dataset.extract_patches(0, patch_size=40, stride=stride, batch_size=128)\n",
    "        patch2 = patches[0,:,:,:]\n",
    "        patch2 = torch.rot90(patch2, dims=(1, 2))\n",
    "        # check if patch1 and patch2 are the same use torch.allclose\n",
    "        TestAssertions.assert_eq(torch.allclose(patch1, patch2), True, f\"Patch 1 and Patch 2 should be the same, {patch1.shape}, {patch2.shape}\")\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    @unit_test\n",
    "    def read_all_patches():\n",
    "        dataset = Train400(\"data/Train400\")\n",
    "        patches = dataset.read_all_patches(patch_size=40, stride=6)\n",
    "        print(patches.shape)\n",
    "        noisy_dataset = NoisyPatchDataset(patches, sigma=(0, 50))\n",
    "        TestAssertions.assert_eq(len(noisy_dataset), 204800, \"Noisy dataset should have 204800 patches\")\n",
    "\n",
    "run_unit_tests(Tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ee542929",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnCNN(nn.Module):\n",
    "    def __init__(self, num_layers=17, num_channels=64, kernel_size=3, image_channels=1, padding=1):\n",
    "        super(DnCNN, self).__init__()\n",
    "        layers = []\n",
    "\n",
    "        layers.append(nn.Conv2d(in_channels=image_channels, out_channels=num_channels, kernel_size=kernel_size, padding=padding, bias=True))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        for _ in range(num_layers-2):\n",
    "            layers.append(nn.Conv2d(in_channels=num_channels, out_channels=num_channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(num_channels, eps=0.0001, momentum = 0.95))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        layers.append(nn.Conv2d(in_channels=num_channels, out_channels=image_channels, kernel_size=kernel_size, padding=padding, bias=True))\n",
    "        self.dncnn = nn.Sequential(*layers)\n",
    "\n",
    "        # Initialize weights\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                init.orthogonal_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        residual = y - self.dncnn(x)\n",
    "        return residual\n",
    "\n",
    "def save_checkpoint(model, epoch, save_dir: Path):\n",
    "    if not save_dir.exists():\n",
    "        save_dir.mkdir(parents=True)\n",
    "    torch.save(model.state_dict(), save_dir / f'model_{epoch:03d}.pth')\n",
    "\n",
    "def load_checkpoint(model, save_dir):\n",
    "    checkpoints = list(save_dir.glob('model_*.pth'))\n",
    "    if len(checkpoints) == 0:\n",
    "        print(\"No checkpoints found, train from beginning\")\n",
    "        return\n",
    "    # sort the checkpoints by the epoch number\n",
    "    checkpoints = sorted(checkpoints, key=lambda x: int(x.stem.split('_')[-1]), reverse=True)\n",
    "\n",
    "    # get the latest checkpoint\n",
    "    latest_checkpoint = checkpoints[0]\n",
    "    model.load_state_dict(torch.load(latest_checkpoint))\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532d30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoints found, train from beginning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                              \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[127]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Create progress bar for batches within this epoch\u001b[39;00m\n\u001b[32m     24\u001b[39m pbar = tqdm(dataloader, desc=\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMAX_EPOCH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m, leave=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_patches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatches\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_cuda\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnoisy_patches\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoisy_patches\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/WorkSpace/cs7180/Gaussian-Denoiser/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/WorkSpace/cs7180/Gaussian-Denoiser/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:730\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m730\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprofiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecord_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_profile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sampler_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;49;00m\n\u001b[32m    733\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-arg]\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/WorkSpace/cs7180/Gaussian-Denoiser/.venv/lib/python3.12/site-packages/torch/autograd/profiler.py:793\u001b[39m, in \u001b[36mrecord_function.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m    791\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_scripting():\n\u001b[32m    792\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch._C.DisableTorchFunctionSubclass():\n\u001b[32m--> \u001b[39m\u001b[32m793\u001b[39m         \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprofiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_record_function_exit\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_RecordFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    795\u001b[39m     torch.ops.profiler._record_function_exit(record)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/WorkSpace/cs7180/Gaussian-Denoiser/.venv/lib/python3.12/site-packages/torch/_ops.py:1057\u001b[39m, in \u001b[36mTorchBindOpOverload.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args: _P.args, **kwargs: _P.kwargs) -> _T:\n\u001b[32m-> \u001b[39m\u001b[32m1057\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_must_dispatch_in_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1058\u001b[39m         \u001b[38;5;66;03m# When any inputs are FakeScriptObject, we need to\u001b[39;00m\n\u001b[32m   1059\u001b[39m         \u001b[38;5;66;03m# skip c++ dispatcher and dispatch in python through _get_dispatch of python_dispatcher\u001b[39;00m\n\u001b[32m   1060\u001b[39m         \u001b[38;5;66;03m# because C++ dispatcher will check the schema and cannot recognize FakeScriptObject.\u001b[39;00m\n\u001b[32m   1061\u001b[39m         \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   1062\u001b[39m         \u001b[38;5;66;03m# Note:\u001b[39;00m\n\u001b[32m   1063\u001b[39m         \u001b[38;5;66;03m# 1. We only register the torchbind op temporarily as effectful op because we only want\u001b[39;00m\n\u001b[32m   1064\u001b[39m         \u001b[38;5;66;03m#    the effect token functionalization logic to be applied during tracing. Otherwise, the behavior\u001b[39;00m\n\u001b[32m   1065\u001b[39m         \u001b[38;5;66;03m#    of the eagerly executing the op might change after tracing.\u001b[39;00m\n\u001b[32m   1066\u001b[39m         \u001b[38;5;66;03m# 2. We don't want to register the op as effectful for all torchbind ops in ctor because this might\u001b[39;00m\n\u001b[32m   1067\u001b[39m         \u001b[38;5;66;03m#    cause unexpected behavior for some autograd.profiler ops e.g. profiler._record_function_exit._RecordFunction.\u001b[39;00m\n\u001b[32m   1068\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._register_as_effectful_op_temporarily():\n\u001b[32m   1069\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dispatch_in_python(\n\u001b[32m   1070\u001b[39m                 \u001b[38;5;28mself\u001b[39m._fallthrough_keys(), *args, **kwargs\n\u001b[32m   1071\u001b[39m             )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/WorkSpace/cs7180/Gaussian-Denoiser/.venv/lib/python3.12/site-packages/torch/_ops.py:1117\u001b[39m, in \u001b[36m_must_dispatch_in_python\u001b[39m\u001b[34m(args, kwargs)\u001b[39m\n\u001b[32m   1116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_must_dispatch_in_python\u001b[39m(args, kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpytree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtree_any\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1118\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[43m            \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_library\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfake_class_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFakeScriptObject\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1121\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1122\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/WorkSpace/cs7180/Gaussian-Denoiser/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py:1645\u001b[39m, in \u001b[36mtree_any\u001b[39m\u001b[34m(pred, tree, is_leaf)\u001b[39m\n\u001b[32m   1641\u001b[39m     flat_args = tree_iter(tree, is_leaf=is_leaf)\n\u001b[32m   1642\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mmap\u001b[39m(pred, flat_args))\n\u001b[32m-> \u001b[39m\u001b[32m1645\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtree_any\u001b[39m(\n\u001b[32m   1646\u001b[39m     pred: Callable[[Any], \u001b[38;5;28mbool\u001b[39m],\n\u001b[32m   1647\u001b[39m     tree: PyTree,\n\u001b[32m   1648\u001b[39m     is_leaf: Optional[Callable[[PyTree], \u001b[38;5;28mbool\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1649\u001b[39m ) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m   1650\u001b[39m     flat_args = tree_iter(tree, is_leaf=is_leaf)\n\u001b[32m   1651\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mmap\u001b[39m(pred, flat_args))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = DnCNN()\n",
    "load_checkpoint(model, SAVE_DIR)\n",
    "model.train()\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss(reduction = 'sum') \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[30, 60, 90], gamma=0.2)  # learning rates\n",
    "\n",
    "training_dataset = Train400(\"data/Train400\")\n",
    "patches = training_dataset.read_all_patches(patch_size=40, stride=6, batch_size=128)\n",
    "# convert patches to float32 and normalize to [0, 1]\n",
    "patches = patches.to(torch.float32) / 255.0\n",
    "noisy_dataset = NoisyPatchDataset(patches, sigma=(0, 50))\n",
    "\n",
    "for epoch in range(MAX_EPOCH):\n",
    "\n",
    "    dataloader = DataLoader(noisy_dataset, batch_size=128, shuffle=True)\n",
    "    epoch_loss = 0\n",
    "\n",
    "    # Create progress bar for batches within this epoch\n",
    "    pbar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{MAX_EPOCH}', leave=False)\n",
    "    \n",
    "    for batch_idx, (noisy_patches, patches) in enumerate(pbar):\n",
    "        if use_cuda:\n",
    "            noisy_patches = noisy_patches.cuda()\n",
    "            patches = patches.cuda()\n",
    "\n",
    "        output = model(noisy_patches)\n",
    "        loss = criterion(output, patches)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update progress bar with current loss\n",
    "        avg_loss = epoch_loss / (batch_idx + 1)\n",
    "        pbar.set_postfix({'Loss': f'{loss.item():.4f}', 'Avg Loss': f'{avg_loss:.4f}'})\n",
    "\n",
    "    scheduler.step()\n",
    "    if epoch % 10 == 0:\n",
    "        save_checkpoint(model, epoch, SAVE_DIR)\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
